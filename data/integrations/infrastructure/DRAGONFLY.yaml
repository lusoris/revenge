doc_title: Dragonfly Integration
doc_category: integration
created_date: '2026-01-31'
overall_status: âœ… Complete
status_design: âœ…
status_design_notes: '-'
status_sources: âœ…
status_sources_notes: '-'
status_instructions: âœ…
status_instructions_notes: '-'
status_code: ðŸ”´
status_code_notes: '-'
status_linting: ðŸ”´
status_linting_notes: '-'
status_unit_testing: ðŸ”´
status_unit_testing_notes: '-'
status_integration_testing: ðŸ”´
status_integration_testing_notes: '-'
technical_summary: '> High-performance Redis-compatible cache'
wiki_tagline: '> Fast distributed caching with Dragonfly'
wiki_overview: Dragonfly provides high-speed caching for Revenge. Stores session data, API responses, and frequently accessed
  metadata in memory. Redis-compatible so existing tools work. Dramatically faster than Redis with lower memory usage. Required
  for multi-server deployments, optional but recommended for single-server.
sources:
- name: Dragonfly Documentation
  url: https://www.dragonflydb.io/docs
  note: Auto-resolved from dragonfly
- name: pgx PostgreSQL Driver
  url: https://pkg.go.dev/github.com/jackc/pgx/v5
  note: Auto-resolved from pgx
- name: PostgreSQL Arrays
  url: https://www.postgresql.org/docs/current/arrays.html
  note: Auto-resolved from postgresql-arrays
- name: PostgreSQL JSON Functions
  url: https://www.postgresql.org/docs/current/functions-json.html
  note: Auto-resolved from postgresql-json
- name: Prometheus Go Client
  url: https://pkg.go.dev/github.com/prometheus/client_golang/prometheus
  note: Auto-resolved from prometheus
- name: Prometheus Metric Types
  url: https://prometheus.io/docs/concepts/metric_types/
  note: Auto-resolved from prometheus-metrics
- name: River Job Queue
  url: https://pkg.go.dev/github.com/riverqueue/river
  note: Auto-resolved from river
- name: rueidis
  url: https://pkg.go.dev/github.com/redis/rueidis
  note: Auto-resolved from rueidis
- name: rueidis GitHub README
  url: https://github.com/redis/rueidis
  note: Auto-resolved from rueidis-docs
- name: Typesense API
  url: https://typesense.org/docs/latest/api/
  note: Auto-resolved from typesense
- name: Typesense Go Client
  url: https://github.com/typesense/typesense-go
  note: Auto-resolved from typesense-go
design_refs:
- title: 01_ARCHITECTURE
  path: ../../architecture/01_ARCHITECTURE.md
- title: 02_DESIGN_PRINCIPLES
  path: ../../architecture/02_DESIGN_PRINCIPLES.md
- title: 03_METADATA_SYSTEM
  path: ../../architecture/03_METADATA_SYSTEM.md
integration_name: Dragonfly
integration_id: dragonfly
external_service: Dragonfly
auth_method: password
architecture_diagram: |-
  ```mermaid
  flowchart LR
      subgraph Layer1["Layer 1"]
          node1[["Server<br/>(Services)"]]
          node2[("rueidis<br/>(Redis Client<br/>with Auto-")]
          node3["Dragonfly<br/>Server"]
      end

      subgraph Layer2["Layer 2"]
          node4["sturdyc<br/>(Coalescing)"]
      end

      %% Connections
      node3 --> node4

      %% Styling
      style Layer1 fill:#1976D2,stroke:#1976D2,color:#fff
      style Layer2 fill:#388E3C,stroke:#388E3C,color:#fff
  ```
connection_details: |
  **Client**: rueidis (high-performance Redis client with auto-pipelining)
  **Protocol**: Redis RESP3
  **Compatibility**: Redis-compatible (all Redis commands work)
  **Authentication**: Password-based (optional)

  **Connection String Format**:
  ```
  redis://[:password@]host:port[/database]
  ```
cache_architecture: |
  **Two-Tier Caching**:
  - **L1 Cache**: otter (in-memory, process-local, TTL-based)
  - **L2 Cache**: Dragonfly (distributed, shared across servers)

  **Cache Flow**:
  1. Check L1 (otter) - fastest, local
  2. If miss, check L2 (Dragonfly) - distributed
  3. If miss, fetch from PostgreSQL
  4. Store in both L1 and L2 for future requests

  **Request Coalescing**: sturdyc prevents stampede by coalescing concurrent requests
key_features: |
  **Advantages over Redis**:
  - 25x faster for certain workloads
  - Lower memory usage (50% reduction)
  - Multi-threaded architecture (Redis is single-threaded)
  - Vertical scaling with more CPU cores
  - Automatic memory defragmentation

  **Use Cases in Revenge**:
  - Session token storage (fast lookups)
  - Metadata cache (movies, shows, artists)
  - API response cache (external provider responses)
  - Rate limiting counters
  - Real-time activity tracking
  - EPG program guide cache
module_structure: |
  ```
  internal/cache/
  â”œâ”€â”€ module.go                    # fx module
  â”œâ”€â”€ dragonfly.go                 # Dragonfly client
  â”œâ”€â”€ l1.go                        # otter L1 cache
  â”œâ”€â”€ l2.go                        # rueidis L2 cache
  â”œâ”€â”€ sturdyc.go                   # Request coalescing
  â”œâ”€â”€ keys.go                      # Cache key utilities
  â””â”€â”€ cache_test.go
  ```
key_interfaces: |
  ```go
  // Cache interface (unified L1 + L2)
  type Cache interface {
    Get(ctx context.Context, key string) ([]byte, error)
    Set(ctx context.Context, key string, value []byte, ttl time.Duration) error
    Delete(ctx context.Context, key string) error
    Exists(ctx context.Context, key string) (bool, error)
    Invalidate(ctx context.Context, pattern string) error
  }

  // Configuration
  type DragonflyConfig struct {
    Addresses  []string      `yaml:"addresses"`
    Password   string        `yaml:"password"`
    DB         int           `yaml:"db"`
    PoolSize   int           `yaml:"pool_size"`
    MaxRetries int           `yaml:"max_retries"`
    TLS        bool          `yaml:"tls"`
  }

  // L1 Cache Config (otter)
  type L1Config struct {
    MaxSize  int           `yaml:"max_size"`
    TTL      time.Duration `yaml:"ttl"`
  }
  ```
dependencies: |
  **Go Packages**:
  - `github.com/redis/rueidis` - High-performance Redis client
  - `github.com/maypok86/otter` - L1 in-memory cache
  - `github.com/viccon/sturdyc` - Request coalescing
  - `go.uber.org/fx` - Dependency injection

  **External Services**:
  - Dragonfly server (recommended) or Redis 6.0+ (fallback)
env_vars: |
  ```bash
  # Dragonfly connection
  DRAGONFLY_ADDRESSES=localhost:6379
  DRAGONFLY_PASSWORD=secret
  DRAGONFLY_DB=0
  DRAGONFLY_POOL_SIZE=10
  DRAGONFLY_TLS=false

  # L1 cache (otter)
  CACHE_L1_MAX_SIZE=10000
  CACHE_L1_TTL=5m

  # L2 cache (Dragonfly)
  CACHE_L2_TTL=1h
  ```
config_keys: |
  ```yaml
  cache:
    dragonfly:
      addresses:
        - localhost:6379
      password: ${DRAGONFLY_PASSWORD}
      db: 0
      pool_size: 10
      max_retries: 3
      tls: false

    l1:
      max_size: 10000
      ttl: 5m

    l2:
      ttl: 1h
  ```
component_interaction: |
  **Cache Read** (with L1 + L2):
  1. Service requests data for key "movie:123"
  2. Check otter L1 cache (in-memory)
  3. If hit, return immediately (microseconds)
  4. If miss, check Dragonfly L2 cache
  5. If hit, store in L1 and return (milliseconds)
  6. If miss, fetch from PostgreSQL
  7. Store in both L1 and L2
  8. Return data

  **Cache Invalidation**:
  1. Content updated in database
  2. Service calls cache.Invalidate("movie:123")
  3. Delete from L1 (otter)
  4. Delete from L2 (Dragonfly via rueidis)
  5. Next request rebuilds cache

  **Request Coalescing** (with sturdyc):
  1. 100 concurrent requests for "movie:123" hit server
  2. sturdyc detects duplicate in-flight requests
  3. Only one request proceeds to fetch data
  4. Other 99 requests wait for the result
  5. All 100 requests receive the same result
  6. Prevents database stampede
api_endpoints: |
  **Health Check**:
  ```
  GET /api/v1/health/cache
  ```

  **Response**:
  ```json
  {
    "status": "healthy",
    "dragonfly": {
      "connected": true,
      "version": "1.15.0"
    },
    "l1_stats": {
      "size": 4523,
      "hit_rate": 0.87,
      "evictions": 123
    },
    "l2_stats": {
      "hit_rate": 0.72
    }
  }
  ```

  **Cache Stats**:
  ```
  GET /api/v1/admin/cache/stats
  ```
common_operations: |
  **Session Storage**:
  ```go
  // Store session (30-minute TTL)
  cache.Set(ctx, "session:"+token, sessionData, 30*time.Minute)

  // Retrieve session
  data, err := cache.Get(ctx, "session:"+token)
  ```

  **Metadata Cache**:
  ```go
  // Cache TMDb movie data (1 hour TTL)
  cache.Set(ctx, "tmdb:movie:550", movieJSON, 1*time.Hour)
  ```

  **Rate Limiting**:
  ```go
  // Increment counter with expiry
  client.Do(ctx, client.B().Incr().Key("ratelimit:user:123").Build())
  client.Do(ctx, client.B().Expire().Key("ratelimit:user:123").Seconds(60).Build())
  ```
unit_tests: |
  ```go
  func TestDragonflyConnection(t *testing.T) {
    // Test connection establishment
  }

  func TestL1L2Cache(t *testing.T) {
    // Test two-tier cache behavior
  }

  func TestSturdycCoalescing(t *testing.T) {
    // Test request coalescing prevents stampede
  }
  ```
integration_tests: |
  ```go
  func TestDragonfly_FullWorkflow(t *testing.T) {
    // Use testcontainers to spin up Dragonfly
    // Test cache operations, invalidation, TTL expiry
  }
  ```
monitoring: |
  **Metrics Exposed** (via Prometheus):
  - `cache_l1_hits_total` - L1 cache hits
  - `cache_l1_misses_total` - L1 cache misses
  - `cache_l2_hits_total` - L2 cache hits
  - `cache_l2_misses_total` - L2 cache misses
  - `cache_request_coalescing_total` - Requests coalesced by sturdyc
  - `dragonfly_connected` - Connection status (0/1)
performance_tuning: |
  **L1 Cache Sizing**:
  - `max_size` should be based on available memory
  - Monitor eviction rate; if high, increase size
  - Keep TTL short (5-10 minutes) for fresh data

  **L2 Cache Tuning**:
  - Use longer TTL (1-24 hours) for stable data
  - Monitor hit rate; target 70%+ for good performance
  - Use Dragonfly's multi-threading for high concurrency

  **Dragonfly Memory**:
  - Allocate ~25% of total RAM to Dragonfly
  - Monitor memory usage with `INFO MEMORY`
  - Enable maxmemory-policy (e.g., allkeys-lru)
