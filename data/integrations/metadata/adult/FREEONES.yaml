doc_title: FreeOnes Integration
doc_category: integration
created_date: '2026-01-31'
overall_status: âœ… Complete
status_design: âœ…
status_design_notes: '-'
status_sources: âœ…
status_sources_notes: '-'
status_instructions: âœ…
status_instructions_notes: '-'
status_code: ðŸ”´
status_code_notes: '-'
status_linting: ðŸ”´
status_linting_notes: '-'
status_unit_testing: ðŸ”´
status_unit_testing_notes: '-'
status_integration_testing: ðŸ”´
status_integration_testing_notes: '-'
technical_summary: '> ENRICHMENT-only performer metadata provider for QAR content'
wiki_tagline: '> FreeOnes - Performer enrichment for Whisparr/StashDB'
wiki_overview: ENRICHMENT-only metadata source for QAR performers (crew). Provides additional biographical data, aliases,
  and social media links not available in StashDB. **Web scraping** with GraphQL-like API. Used to supplement existing performer
  profiles. **Optional proxy/VPN routing** recommended (via HTTP_CLIENT service).
sources:
- name: Dragonfly Documentation
  url: https://www.dragonflydb.io/docs
  note: Auto-resolved from dragonfly
- name: Go io
  url: https://pkg.go.dev/io
  note: Auto-resolved from go-io
- name: River Job Queue
  url: https://pkg.go.dev/github.com/riverqueue/river
  note: Auto-resolved from river
- name: PuerkitoBio/goquery
  url: https://pkg.go.dev/github.com/PuerkitoBio/goquery
  note: HTML parsing for web scraping
- name: golang.org/x/time
  url: https://pkg.go.dev/golang.org/x/time
  note: Rate limiting
design_refs:
- title: 03_METADATA_SYSTEM
  path: ../../../architecture/03_METADATA_SYSTEM.md
- title: WHISPARR (PRIMARY for QAR)
  path: ../../servarr/WHISPARR.md
- title: STASHDB (also SUPPLEMENTARY)
  path: ./STASHDB.md
- title: THEPORNDB
  path: ./THEPORNDB.md
- title: HTTP_CLIENT (proxy/VPN support)
  path: ../../../services/HTTP_CLIENT.md
- title: ADULT_CONTENT_SYSTEM (QAR module)
  path: ../../../features/adult/ADULT_CONTENT_SYSTEM.md
- title: DATA_RECONCILIATION
  path: ../../../features/adult/DATA_RECONCILIATION.md
integration_name: FreeOnes
integration_id: freeones
external_service: FreeOnes
api_base_url: https://www.freeones.com
data_access_method: web_scraping
architecture_diagram: |-
  ```mermaid
  flowchart TD
      node1["Revenge<br/>Performer<br/>Enrichment"]
      subgraph row1[ ]
          direction LR
          node2[("Whisparr/StashDB<br/>(performer base)")]
          node3["FreeOnes<br/>(additional<br/>details)"]
      end
      node4(["HTTP_CLIENT<br/>(RECOMMENDED<br/>proxy/VPN)"])
      node5["Rate Limiter<br/>(2 req/sec)"]
      node2 --> node3
      node1 --> node2
      node3 --> node4
      node4 --> node5

      %% Hide row subgraph borders
      style row1 fill:transparent,stroke:transparent
  ```
api_details: |
  **Data Access**: Web scraping + internal API
  **Base URL**: `https://www.freeones.com`
  **Authentication**: None required (public pages)
  **Rate Limit**: Self-imposed 2 requests per second (be respectful)

  **Scraping Targets**:
  - `/name/performer-slug/profile` - Main profile page
  - `/name/performer-slug/bio` - Biographical details
  - `/name/performer-slug/links` - Social media links
  - `/api/v1/performers/{slug}` - Internal API (JSON, may change)

  **Search**:
  - `/?s=performer+name&t=profiles` - Search results page
  - Returns list of matching performers with slugs

  **IMPORTANT**: FreeOnes does not have a public API. Web scraping should:
  - Respect robots.txt
  - Use reasonable rate limits (2 req/sec)
  - Use proxy/VPN to avoid IP blocks
  - Cache aggressively (data changes infrequently)
database_schema: |
  **Schema**: `qar` (pirate-themed obfuscation)

  ```sql
  -- FreeOnes performer mappings
  CREATE TABLE qar.freeones_mappings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    performer_id UUID NOT NULL REFERENCES qar.crew(id),
    freeones_slug VARCHAR(255) NOT NULL,
    freeones_url TEXT,

    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now(),

    UNIQUE(performer_id)
  );
  CREATE INDEX idx_freeones_slug ON qar.freeones_mappings(freeones_slug);

  -- Enriched performer data from FreeOnes
  CREATE TABLE qar.performer_enrichment (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    performer_id UUID NOT NULL REFERENCES qar.crew(id),
    source VARCHAR(50) NOT NULL DEFAULT 'freeones',

    -- Biographical data
    real_name VARCHAR(255),
    birthdate DATE,
    birthplace VARCHAR(255),
    nationality VARCHAR(100),
    ethnicity VARCHAR(100),
    hair_color VARCHAR(50),
    eye_color VARCHAR(50),
    height_cm INT,
    weight_kg INT,
    measurements VARCHAR(50),         -- e.g., "34D-24-35"
    cup_size VARCHAR(10),
    tattoos TEXT,
    piercings TEXT,

    -- Career data
    career_start_year INT,
    career_end_year INT,              -- NULL if still active
    career_status VARCHAR(50),        -- 'active', 'retired', 'unknown'

    -- Statistics
    scene_count INT,
    award_count INT,

    -- Social links (stored as JSONB for flexibility)
    social_links JSONB,               -- [{"platform": "twitter", "url": "..."}]

    -- Aliases (additional to main performer record)
    aliases TEXT[],

    fetched_at TIMESTAMPTZ DEFAULT now(),
    expires_at TIMESTAMPTZ NOT NULL,

    UNIQUE(performer_id, source)
  );
  CREATE INDEX idx_performer_enrichment_expires ON qar.performer_enrichment(expires_at);
  ```
module_structure: |
  ```
  internal/metadata/providers/freeones/
  â”œâ”€â”€ module.go                    # fx module
  â”œâ”€â”€ client.go                    # HTTP client with scraping
  â”œâ”€â”€ provider.go                  # Enrichment provider interface impl
  â”œâ”€â”€ scraper.go                   # HTML parsing logic
  â”œâ”€â”€ parser.go                    # Profile data extraction
  â”œâ”€â”€ search.go                    # Performer search
  â”œâ”€â”€ ratelimit.go                 # Rate limiter (2/sec)
  â””â”€â”€ freeones_test.go
  ```
key_interfaces: |
  ```go
  // FreeOnes enrichment provider
  type FreeOnesProvider struct {
    httpFactory  httpclient.ClientFactory
    rateLimiter  *rate.Limiter
    cache        Cache
  }

  // Enrichment-only provider interface
  type PerformerEnrichmentProvider interface {
    // Search for performer on FreeOnes
    SearchPerformer(ctx context.Context, name string) ([]PerformerSearchResult, error)

    // Get full profile by FreeOnes slug
    GetPerformerProfile(ctx context.Context, slug string) (*EnrichedProfile, error)

    // Match performer from existing StashDB/TPDB ID
    MatchPerformer(ctx context.Context, stashdbID, tpdbID string, name string) (*EnrichedProfile, error)

    // Provider metadata
    ProviderName() string  // Returns "freeones"
    IsEnrichmentOnly() bool // Returns true
  }

  // Search result from FreeOnes
  type PerformerSearchResult struct {
    Slug       string `json:"slug"`
    Name       string `json:"name"`
    ImageURL   string `json:"image"`
    ProfileURL string `json:"url"`
    Rank       int    `json:"rank"`      // FreeOnes popularity rank
    Active     bool   `json:"active"`    // Still active in industry
  }

  // Enriched profile data
  type EnrichedProfile struct {
    // Identity
    Slug        string   `json:"slug"`
    Name        string   `json:"name"`
    RealName    string   `json:"real_name,omitempty"`
    Aliases     []string `json:"aliases"`

    // Biographical
    Birthdate   string   `json:"birthdate,omitempty"`
    Birthplace  string   `json:"birthplace,omitempty"`
    Nationality string   `json:"nationality,omitempty"`
    Ethnicity   string   `json:"ethnicity,omitempty"`

    // Physical
    Height       int    `json:"height_cm,omitempty"`
    Weight       int    `json:"weight_kg,omitempty"`
    Measurements string `json:"measurements,omitempty"`
    CupSize      string `json:"cup_size,omitempty"`
    HairColor    string `json:"hair_color,omitempty"`
    EyeColor     string `json:"eye_color,omitempty"`
    Tattoos      string `json:"tattoos,omitempty"`
    Piercings    string `json:"piercings,omitempty"`

    // Career
    CareerStart  int    `json:"career_start,omitempty"`
    CareerEnd    int    `json:"career_end,omitempty"`   // 0 if active
    CareerStatus string `json:"career_status"`          // active, retired

    // Statistics
    Rank       int `json:"rank"`
    SceneCount int `json:"scene_count"`
    AwardCount int `json:"award_count"`

    // Social links
    SocialLinks []SocialLink `json:"social_links"`

    // Images
    ProfileImage   string   `json:"profile_image"`
    GalleryImages  []string `json:"gallery_images"`
  }

  // Social media link
  type SocialLink struct {
    Platform string `json:"platform"`  // twitter, instagram, onlyfans, etc.
    URL      string `json:"url"`
    Username string `json:"username,omitempty"`
  }
  ```
dependencies: |
  **Go Packages**:
  - `net/http` - HTTP client
  - `github.com/PuerkitoBio/goquery` - HTML parsing (jQuery-like)
  - `golang.org/x/time/rate` - Rate limiting (2 req/sec)
  - `github.com/jackc/pgx/v5` - PostgreSQL driver
  - `github.com/riverqueue/river` - Background enrichment jobs
  - `go.uber.org/fx` - Dependency injection

  **External**:
  - FreeOnes website (web scraping, no official API)

  **Internal Services**:
  - HTTP_CLIENT - Proxy/VPN routing (RECOMMENDED for scraping)
  - Whisparr/StashDB - Base performer data to enrich
env_vars: |
  ```bash
  # FreeOnes integration
  FREEONES_ENABLED=true

  # Rate limiting (be respectful)
  FREEONES_RATE_LIMIT=2
  FREEONES_RATE_WINDOW=1s

  # Caching
  FREEONES_CACHE_TTL=168h           # 7 days

  # Proxy/VPN (RECOMMENDED for scraping)
  FREEONES_PROXY_ENABLED=true
  FREEONES_PROXY_URL=socks5://127.0.0.1:9050
  ```
config_keys: |
  ```yaml
  metadata:
    providers:
      freeones:
        enabled: true
        rate_limit: 2
        rate_window: 1s
        cache_ttl: 168h              # 7 days

        # ENRICHMENT role only (not primary or fallback)
        role: enrichment

        # Proxy/VPN support (RECOMMENDED for web scraping)
        proxy:
          enabled: true              # Recommended for scraping
          type: tor
          url: socks5://127.0.0.1:9050

        # Scraping settings
        scraping:
          user_agent: "Mozilla/5.0 (compatible; RevengeBot/1.0)"
          respect_robots_txt: true
          retry_on_block: true
          max_retries: 3

        # Enrichment settings
        enrichment:
          auto_enrich: true          # Auto-enrich new performers
          priority: low              # Background job priority
          batch_size: 10             # Performers per batch job
  ```
component_interaction: |
  **Performer Enrichment Flow**:
  1. New performer added to database (from Whisparr/StashDB)
  2. Enrichment job scheduled via River (low priority, background)
  3. FreeOnesProvider.MatchPerformer() called with name + IDs
  4. Provider searches FreeOnes for performer name
  5. Best match determined by fuzzy name matching
  6. Provider scrapes full profile page
  7. HTML parsed with goquery to extract data
  8. EnrichedProfile returned and merged with existing record
  9. Results cached for 7 days

  **Scraping Flow**:
  1. Check rate limiter (2 req/sec)
  2. Get HTTP client with proxy/VPN (recommended)
  3. Fetch profile page: `GET /name/{slug}/profile`
  4. Parse HTML response with goquery
  5. Extract biographical fields from structured elements
  6. Fetch links page: `GET /name/{slug}/links`
  7. Extract social media URLs
  8. Combine into EnrichedProfile

  **Merging with Existing Data**:
  - Only fill in missing fields (don't overwrite primary source)
  - Append new aliases to existing list
  - Add social links not already present
  - Update enrichment timestamp
scraping_implementation: |
  **HTML Parsing with goquery**:
  ```go
  import "github.com/PuerkitoBio/goquery"

  func (p *FreeOnesProvider) scrapeProfile(
    ctx context.Context,
    slug string,
  ) (*EnrichedProfile, error) {
    // Rate limit
    if err := p.rateLimiter.Wait(ctx); err != nil {
      return nil, fmt.Errorf("rate limit: %w", err)
    }

    // Get HTTP client with proxy
    client, err := p.httpFactory.GetClientForService(ctx, "freeones")
    if err != nil {
      return nil, fmt.Errorf("http client: %w", err)
    }

    // Fetch profile page
    url := fmt.Sprintf("https://www.freeones.com/name/%s/bio", slug)
    req, _ := http.NewRequestWithContext(ctx, "GET", url, nil)
    req.Header.Set("User-Agent", p.userAgent)

    resp, err := client.Do(req)
    if err != nil {
      return nil, fmt.Errorf("fetch page: %w", err)
    }
    defer resp.Body.Close()

    if resp.StatusCode == 404 {
      return nil, ErrPerformerNotFound
    }

    // Parse HTML
    doc, err := goquery.NewDocumentFromReader(resp.Body)
    if err != nil {
      return nil, fmt.Errorf("parse html: %w", err)
    }

    profile := &EnrichedProfile{Slug: slug}

    // Extract name
    profile.Name = doc.Find("h1.performer-name").Text()

    // Extract biography table
    doc.Find(".bio-table tr").Each(func(i int, s *goquery.Selection) {
      label := strings.TrimSpace(s.Find("td:first-child").Text())
      value := strings.TrimSpace(s.Find("td:last-child").Text())

      switch label {
      case "Birthdate":
        profile.Birthdate = value
      case "Birthplace":
        profile.Birthplace = value
      case "Height":
        profile.Height = parseHeight(value)
      case "Weight":
        profile.Weight = parseWeight(value)
      case "Measurements":
        profile.Measurements = value
      case "Hair Color":
        profile.HairColor = value
      case "Eye Color":
        profile.EyeColor = value
      case "Tattoos":
        profile.Tattoos = value
      case "Piercings":
        profile.Piercings = value
      }
    })

    // Extract aliases
    doc.Find(".aliases a").Each(func(i int, s *goquery.Selection) {
      alias := strings.TrimSpace(s.Text())
      if alias != "" && alias != profile.Name {
        profile.Aliases = append(profile.Aliases, alias)
      }
    })

    // Extract profile image
    if img, exists := doc.Find(".profile-image img").Attr("src"); exists {
      profile.ProfileImage = img
    }

    return profile, nil
  }
  ```
enrichment_role: |
  **ENRICHMENT-Only Provider** (not primary or fallback)

  FreeOnes is used **only for enrichment** of existing performer profiles:
  - Does NOT provide scene metadata
  - Does NOT replace Whisparr/StashDB/ThePornDB as primary sources
  - ONLY adds additional biographical data to existing performers

  **Data Enriched**:
  - Additional aliases (stage names)
  - Physical measurements (height, weight, etc.)
  - Career dates (start/end years)
  - Social media links
  - Biographical details (birthplace, nationality)

  **Enrichment Trigger**:
  - Automatic: When new performer added (background job)
  - Manual: Admin requests enrichment for specific performer
  - Scheduled: Periodic refresh of stale enrichment data

  **Implementation**:
  ```go
  // Enrichment job (runs via River)
  type PerformerEnrichmentJob struct {
    PerformerID uuid.UUID `json:"performer_id"`
    Name        string    `json:"name"`
  }

  func (j *PerformerEnrichmentJob) Work(ctx context.Context) error {
    // Get existing performer
    performer, err := j.repo.GetPerformer(ctx, j.PerformerID)
    if err != nil {
      return err
    }

    // Search FreeOnes
    results, err := j.freeones.SearchPerformer(ctx, performer.Name)
    if err != nil || len(results) == 0 {
      return nil // Not found, skip
    }

    // Get full profile for best match
    profile, err := j.freeones.GetPerformerProfile(ctx, results[0].Slug)
    if err != nil {
      return err
    }

    // Merge enrichment data
    j.mergeEnrichment(performer, profile)

    // Save updated performer
    return j.repo.UpdatePerformer(ctx, performer)
  }
  ```
proxy_vpn_support: |
  **Proxy/VPN Routing** (RECOMMENDED for web scraping)

  FreeOnes scraping should use proxy/VPN for:
  - **IP Protection**: Avoid blocking of server IP
  - **Privacy**: Hide scraping activity
  - **Reliability**: Rotate IPs if blocked

  **RECOMMENDED**: Enable proxy for FreeOnes scraping
  - Web scraping without proxy may result in IP blocks
  - Tor provides anonymity and IP rotation
  - Consider residential proxies for higher reliability

  **Configuration**:
  ```yaml
  metadata:
    providers:
      freeones:
        proxy:
          enabled: true              # RECOMMENDED
          type: tor
          url: socks5://127.0.0.1:9050
  ```

  **Handling Blocks**:
  ```go
  func (p *FreeOnesProvider) handleResponse(resp *http.Response) error {
    switch resp.StatusCode {
    case 200:
      return nil
    case 403, 429:
      // Blocked or rate limited - rotate proxy
      p.httpFactory.RotateProxy(ctx, "freeones")
      return ErrBlocked
    case 503:
      // Cloudflare challenge - may need browser automation
      return ErrCloudflareChallenge
    default:
      return fmt.Errorf("unexpected status: %d", resp.StatusCode)
    }
  }
  ```
error_handling: |
  **HTTP Error Codes**:
  - 404 Not Found â†’ Performer page doesn't exist
  - 403 Forbidden â†’ IP blocked or Cloudflare protection
  - 429 Too Many Requests â†’ Rate limited (slow down)
  - 503 Service Unavailable â†’ Cloudflare challenge

  **Scraping Errors**:
  - Page structure changed â†’ Update selectors, log warning
  - Data extraction failed â†’ Return partial data
  - Cloudflare challenge â†’ Retry with different proxy/IP

  **Retry Strategy**:
  - 403/429: Rotate proxy, retry after 30 seconds
  - 503: Wait 60 seconds, retry with new proxy
  - Network errors: Retry 3 times with exponential backoff
unit_tests: |
  ```go
  func TestFreeOnes_ParseProfile(t *testing.T) {
    // Test HTML parsing with sample page
    html := `<html>
      <h1 class="performer-name">Test Performer</h1>
      <div class="bio-table">
        <tr><td>Birthdate</td><td>January 1, 1990</td></tr>
        <tr><td>Height</td><td>5'6" (168 cm)</td></tr>
      </div>
    </html>`

    doc, _ := goquery.NewDocumentFromReader(strings.NewReader(html))
    profile := parseProfile(doc)

    assert.Equal(t, "Test Performer", profile.Name)
    assert.Equal(t, 168, profile.Height)
  }

  func TestFreeOnes_Search(t *testing.T) {
    // Test search result parsing
  }

  func TestFreeOnes_RateLimit(t *testing.T) {
    // Ensure rate limit is enforced (2 req/sec)
  }
  ```
integration_tests: |
  ```go
  func TestFreeOnes_FullEnrichment(t *testing.T) {
    if testing.Short() {
      t.Skip("skipping integration test")
    }

    // Requires proxy/VPN for reliable testing
    provider := NewFreeOnesProvider(httpFactory)

    // Search for known performer
    results, err := provider.SearchPerformer(context.Background(), "test performer")
    require.NoError(t, err)

    if len(results) > 0 {
      // Get full profile
      profile, err := provider.GetPerformerProfile(
        context.Background(),
        results[0].Slug,
      )
      require.NoError(t, err)
      assert.NotEmpty(t, profile.Name)
    }
  }
  ```
caching_strategy: |
  **Cache Layers**:
  - **L1**: In-memory cache (otter) for search results (1 hour TTL)
  - **L2**: Dragonfly cache for profiles (7 day TTL)
  - **Database**: performer_enrichment table (permanent until refresh)

  **Cache Keys**:
  - `freeones:search:{query}` - Search results
  - `freeones:profile:{slug}` - Full profile data
  - `freeones:links:{slug}` - Social media links

  **Long TTL Rationale**:
  - Performer data changes infrequently
  - Web scraping should be minimized
  - 7-day cache reduces load on FreeOnes
best_practices: |
  **Scraping Ethics**:
  - Respect robots.txt directives
  - Use reasonable rate limits (2 req/sec)
  - Identify bot in User-Agent
  - Cache aggressively to minimize requests
  - Don't scrape during high-traffic periods

  **Data Quality**:
  - Validate parsed data before storing
  - Handle missing/null fields gracefully
  - Cross-reference with StashDB/TPDB for verification
  - Log parsing failures for selector updates

  **Proxy Management**:
  - Use proxy pool for IP rotation
  - Monitor for blocks and rotate automatically
  - Consider residential proxies for better reliability
  - Tor provides good anonymity but can be slow

  **Maintenance**:
  - Monitor for HTML structure changes
  - Update selectors when page layout changes
  - Implement alerts for scraping failures
  - Periodically verify data accuracy
