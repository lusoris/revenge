doc_title: Advanced Offloading Architecture
doc_category: technical
created_date: '2026-01-31'
overall_status: âœ… Complete
status_design: âœ…
status_design_notes: Complete offloading architecture
status_sources: âœ…
status_sources_notes: All offloading tools documented
status_instructions: âœ…
status_instructions_notes: Generated from design
status_code: ðŸ”´
status_code_notes: '-'
status_linting: ðŸ”´
status_linting_notes: '-'
status_unit_testing: ðŸ”´
status_unit_testing_notes: '-'
status_integration_testing: ðŸ”´
status_integration_testing_notes: '-'
technical_summary: '> Offload heavy operations to background workers and external
  services


  Complete offloading strategy:

  - **Background Jobs**: River queue for async tasks (transcoding, metadata enrichment)

  - **Caching**: Dragonfly/Rueidis for session storage, rate limiting, API caching

  - **Search**: Typesense for full-text search offloading

  - **Metrics**: Prometheus for monitoring and alerting

  - **Pattern**: Fast HTTP response, queue heavy work, notify on completion'
wiki_tagline: '> Keep your API fast by offloading heavy work to specialized services'
wiki_overview: The Advanced Offloading Architecture ensures fast API response times
  by delegating heavy operations to background workers and specialized services. Transcoding,
  metadata enrichment, and image processing run asynchronously via River queue. Session
  storage and rate limiting use Dragonfly cache. Full-text search queries route to
  Typesense. Metrics collection offloads to Prometheus. The result is a responsive
  API that scales horizontally while handling resource-intensive tasks efficiently.
sources:
- name: Dragonfly Documentation
  url: https://www.dragonflydb.io/docs
  note: Auto-resolved from dragonfly
- name: Uber fx
  url: https://pkg.go.dev/go.uber.org/fx
  note: Auto-resolved from fx
- name: koanf
  url: https://pkg.go.dev/github.com/knadh/koanf/v2
  note: Auto-resolved from koanf
- name: Prometheus Go Client
  url: https://pkg.go.dev/github.com/prometheus/client_golang/prometheus
  note: Auto-resolved from prometheus
- name: Prometheus Metric Types
  url: https://prometheus.io/docs/concepts/metric_types/
  note: Auto-resolved from prometheus-metrics
- name: River Job Queue
  url: https://pkg.go.dev/github.com/riverqueue/river
  note: Auto-resolved from river
- name: rueidis
  url: https://pkg.go.dev/github.com/redis/rueidis
  note: Auto-resolved from rueidis
- name: rueidis GitHub README
  url: https://github.com/redis/rueidis
  note: Auto-resolved from rueidis-docs
- name: Typesense API
  url: https://typesense.org/docs/latest/api/
  note: Auto-resolved from typesense
- name: Typesense Go Client
  url: https://github.com/typesense/typesense-go
  note: Auto-resolved from typesense-go
design_refs:
- title: technical
  path: technical.md
- title: 01_ARCHITECTURE
  path: ../architecture/01_ARCHITECTURE.md
- title: 02_DESIGN_PRINCIPLES
  path: ../architecture/02_DESIGN_PRINCIPLES.md
- title: METADATA_ENRICHMENT
  path: ../patterns/METADATA_ENRICHMENT.md
offloading_principles:
- principle: Fast API responses
  description: HTTP handlers return within 100ms
  implementation: Queue heavy work, return 202 Accepted
- principle: Horizontal scalability
  description: Stateless API servers, shared state in Dragonfly/PostgreSQL
  implementation: Multiple API instances behind load balancer
- principle: Specialized services
  description: Use best tool for each job
  implementation: Typesense for search, River for jobs, Dragonfly for cache
- principle: Graceful degradation
  description: Continue operating when external services fail
  implementation: Cache fallbacks, skip optional enrichment
- principle: Resource isolation
  description: Heavy tasks don't starve API requests
  implementation: Separate worker pool for background jobs
offloading_targets:
  background_jobs:
    service: River job queue
    use_cases:
    - Video transcoding
    - Metadata enrichment
    - Image thumbnail generation
    - Email sending
    - Webhook delivery
    - Database cleanup
    - Library scanning
    pattern: "```go\n// API handler queues job\nfunc (h *Handler) UploadVideo(ctx\
      \ context.Context, req *UploadVideoRequest) (*UploadVideoResponse, error) {\n\
      \    // Save video file metadata to database (fast)\n    video, err := h.repo.Insert(ctx,\
      \ &Video{\n        Title:    req.Title,\n        FilePath: req.FilePath,\n \
      \   })\n    if err != nil {\n        return nil, err\n    }\n\n    // Queue\
      \ transcoding job (async)\n    _, err = h.riverClient.Insert(ctx, &TranscodeVideoArgs{\n\
      \        VideoID: video.ID,\n    }, nil)\n\n    // Return immediately\n    return\
      \ &UploadVideoResponse{\n        VideoID: video.ID,\n        Status:  \"processing\"\
      ,\n    }, nil\n}\n\n// Worker processes job\ntype TranscodeVideoWorker struct\
      \ {\n    river.WorkerDefaults[TranscodeVideoArgs]\n    transcoder *Transcoder\n\
      }\n\nfunc (w *TranscodeVideoWorker) Work(ctx context.Context, job *river.Job[TranscodeVideoArgs])\
      \ error {\n    return w.transcoder.Transcode(ctx, job.Args.VideoID)\n}\n```\n"
  distributed_cache:
    service: Dragonfly (Redis-compatible)
    library: rueidis
    use_cases:
    - Session storage
    - API response caching
    - Rate limiting
    - Temporary data (OTP codes)
    - Distributed locks
    - Playback progress
    pattern: "```go\n// Session storage offloaded to Dragonfly\nfunc (s *SessionService)\
      \ Create(ctx context.Context, userID uuid.UUID) (*Session, error) {\n    session\
      \ := &Session{\n        ID:     uuid.New(),\n        UserID: userID,\n     \
      \   ExpiresAt: time.Now().Add(24 * time.Hour),\n    }\n\n    // Store in Dragonfly,\
      \ not PostgreSQL\n    key := fmt.Sprintf(\"session:%s\", session.ID)\n    data,\
      \ _ := json.Marshal(session)\n    err := s.cache.Do(ctx, s.cache.B().Set().\n\
      \        Key(key).\n        Value(string(data)).\n        Ex(24 * time.Hour).\n\
      \        Build()).Error()\n\n    return session, err\n}\n\n// Rate limiting\
      \ offloaded to Dragonfly\nfunc (r *RateLimiter) Allow(ctx context.Context, userID\
      \ uuid.UUID) (bool, error) {\n    key := fmt.Sprintf(\"ratelimit:%s:%s\", userID,\
      \ time.Now().Format(\"2006-01-02-15\"))\n    count, err := r.cache.Do(ctx, r.cache.B().Incr().Key(key).Build()).AsInt64()\n\
      \    if err != nil {\n        return false, err\n    }\n\n    if count == 1\
      \ {\n        // Set TTL on first request\n        r.cache.Do(ctx, r.cache.B().Expire().Key(key).Seconds(3600).Build())\n\
      \    }\n\n    return count <= 100, nil // 100 requests per hour\n}\n```\n"
  search_engine:
    service: Typesense
    use_cases:
    - Full-text search across all content types
    - Fuzzy search with typo tolerance
    - Faceted filtering
    - Real-time search as you type
    pattern: "```go\n// Search offloaded to Typesense\nfunc (s *SearchService) Search(ctx\
      \ context.Context, query string) ([]SearchResult, error) {\n    searchParams\
      \ := &api.SearchCollectionParams{\n        Q:       query,\n        QueryBy:\
      \ \"title,description,tags\",\n        PerPage: api.PtrInt(20),\n    }\n\n \
      \   // Query Typesense, not PostgreSQL full-text search\n    results, err :=\
      \ s.typesense.Collection(\"movies\").Documents().Search(searchParams)\n    if\
      \ err != nil {\n        return nil, err\n    }\n\n    return s.convertResults(results),\
      \ nil\n}\n\n// Index updates sent to Typesense on content changes\nfunc (s *SearchService)\
      \ IndexMovie(ctx context.Context, movie *Movie) error {\n    doc := map[string]any{\n\
      \        \"id\":          movie.ID.String(),\n        \"title\":       movie.Title,\n\
      \        \"description\": movie.Overview,\n        \"year\":        movie.Year,\n\
      \        \"tags\":        movie.Genres,\n    }\n\n    _, err := s.typesense.Collection(\"\
      movies\").Documents().Create(doc)\n    return err\n}\n```\n"
  metrics_collection:
    service: Prometheus
    use_cases:
    - Request counts and latencies
    - Background job metrics
    - Cache hit rates
    - Database connection pool stats
    pattern: "```go\n// Metrics offloaded to Prometheus (pull model)\nvar (\n    httpRequestsTotal\
      \ = promauto.NewCounterVec(\n        prometheus.CounterOpts{\n            Name:\
      \ \"http_requests_total\",\n            Help: \"Total number of HTTP requests\"\
      ,\n        },\n        []string{\"method\", \"path\", \"status\"},\n    )\n\n\
      \    httpRequestDuration = promauto.NewHistogramVec(\n        prometheus.HistogramOpts{\n\
      \            Name:    \"http_request_duration_seconds\",\n            Help:\
      \    \"HTTP request latency\",\n            Buckets: prometheus.DefBuckets,\n\
      \        },\n        []string{\"method\", \"path\"},\n    )\n)\n\n// Middleware\
      \ records metrics (minimal overhead)\nfunc MetricsMiddleware(next http.Handler)\
      \ http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r\
      \ *http.Request) {\n        start := time.Now()\n        rec := &statusRecorder{ResponseWriter:\
      \ w, statusCode: 200}\n\n        next.ServeHTTP(rec, r)\n\n        duration\
      \ := time.Since(start).Seconds()\n        httpRequestsTotal.WithLabelValues(r.Method,\
      \ r.URL.Path, strconv.Itoa(rec.statusCode)).Inc()\n        httpRequestDuration.WithLabelValues(r.Method,\
      \ r.URL.Path).Observe(duration)\n    })\n}\n```\n"
offloading_patterns:
  pattern_1_async_processing:
    name: Async Background Processing
    problem: Heavy operation blocks HTTP handler
    solution: Queue job, return immediately, notify on completion
    example: "```go\n// BAD: Blocks for minutes\nfunc (h *Handler) ScanLibrary(ctx\
      \ context.Context) error {\n    files, _ := filepath.Glob(\"/media/**/*.mp4\"\
      )\n    for _, file := range files {\n        h.processFile(file) // Takes 1-2\
      \ seconds per file\n    }\n    return nil\n}\n\n// GOOD: Returns immediately\n\
      func (h *Handler) ScanLibrary(ctx context.Context) (*ScanResponse, error) {\n\
      \    scanID := uuid.New()\n\n    _, err := h.riverClient.Insert(ctx, &ScanLibraryArgs{\n\
      \        ScanID: scanID,\n        Path:   \"/media\",\n    }, nil)\n\n    return\
      \ &ScanResponse{\n        ScanID: scanID,\n        Status: \"started\",\n  \
      \  }, err\n}\n```\n"
  pattern_2_lazy_initialization:
    name: Lazy Initialization
    problem: Expensive operation on every request
    solution: Cache result, initialize only once
    example: "```go\n// BAD: Loads config on every request\nfunc (h *Handler) GetSettings(ctx\
      \ context.Context) (*Settings, error) {\n    return h.loadSettingsFromDatabase(ctx)\
      \ // Database query every time\n}\n\n// GOOD: Cache settings in Dragonfly\n\
      func (h *Handler) GetSettings(ctx context.Context) (*Settings, error) {\n  \
      \  // Try cache first\n    cached, err := h.cache.Do(ctx, h.cache.B().Get().Key(\"\
      settings\").Build()).ToString()\n    if err == nil {\n        var settings Settings\n\
      \        json.Unmarshal([]byte(cached), &settings)\n        return &settings,\
      \ nil\n    }\n\n    // Cache miss, load from database\n    settings, err :=\
      \ h.loadSettingsFromDatabase(ctx)\n    if err != nil {\n        return nil,\
      \ err\n    }\n\n    // Store in cache for 5 minutes\n    data, _ := json.Marshal(settings)\n\
      \    h.cache.Do(ctx, h.cache.B().Set().Key(\"settings\").Value(string(data)).Ex(5*time.Minute).Build())\n\
      \n    return settings, nil\n}\n```\n"
  pattern_3_request_coalescing:
    name: Request Coalescing
    problem: Multiple concurrent requests for same resource hit backend
    solution: Use Sturdyc to coalesce requests into single backend call
    example: "```go\n// Using Sturdyc for request coalescing\ncache := sturdyc.New[string,\
      \ *Movie](1000, 10*time.Minute, 5)\n\nfunc (s *MovieService) GetByID(ctx context.Context,\
      \ id uuid.UUID) (*Movie, error) {\n    // Multiple concurrent requests for same\
      \ movie coalesce into single DB query\n    return cache.GetOrFetch(ctx, id.String(),\
      \ func(ctx context.Context) (*Movie, error) {\n        return s.repo.GetByID(ctx,\
      \ id)\n    })\n}\n```\n"
  pattern_4_pagination_offloading:
    name: Pagination Offloading
    problem: Large result sets loaded into memory
    solution: Use database cursor-based pagination
    example: "```go\n// BAD: Loads all results\nfunc (h *Handler) ListMovies(ctx context.Context)\
      \ ([]Movie, error) {\n    return h.repo.GetAll(ctx) // 10000+ rows\n}\n\n//\
      \ GOOD: Paginated with cursor\nfunc (h *Handler) ListMovies(ctx context.Context,\
      \ cursor string, limit int) (*MoviePage, error) {\n    movies, nextCursor, err\
      \ := h.repo.GetPage(ctx, cursor, limit)\n    return &MoviePage{\n        Movies:\
      \     movies,\n        NextCursor: nextCursor,\n        HasMore:    nextCursor\
      \ != \"\",\n    }, err\n}\n```\n"
  pattern_5_compression_offloading:
    name: Compression Offloading
    problem: CPU-intensive compression in HTTP handler
    solution: Use reverse proxy (Traefik/Caddy) for response compression
    implementation: Enable gzip/brotli in Traefik, not in Go code
  pattern_6_static_file_offloading:
    name: Static File Offloading
    problem: Go server serves static assets
    solution: Use CDN or reverse proxy for static files
    implementation: Traefik serves /static/* directly from filesystem
offloading_benefits:
- benefit: Fast API response times
  metric: P95 latency < 100ms
  measurement: Prometheus histogram
- benefit: Horizontal scalability
  metric: Linear scaling to 100+ API instances
  measurement: Load test results
- benefit: Resource isolation
  metric: Background jobs don't affect API latency
  measurement: Separate CPU/memory quotas
- benefit: Improved reliability
  metric: API stays up even if workers crash
  measurement: Uptime monitoring
- benefit: Better user experience
  metric: Users don't wait for slow operations
  measurement: User surveys, session analytics
offloading_anti_patterns:
- anti_pattern: Synchronous email sending
  problem: SMTP timeout blocks HTTP handler
  fix: Use River queue for async email sending
- anti_pattern: In-memory session storage
  problem: Sessions lost on restart, can't scale horizontally
  fix: Store sessions in Dragonfly
- anti_pattern: Database for rate limiting
  problem: Too many writes, poor performance
  fix: Use Dragonfly INCR command
- anti_pattern: PostgreSQL for full-text search
  problem: Slow queries, poor relevance scoring
  fix: Use Typesense for search
- anti_pattern: Inline transcoding
  problem: HTTP request times out after 30 seconds
  fix: Queue transcoding job via River
- anti_pattern: Polling for job status
  problem: Wasteful, adds latency
  fix: Use WebSocket for real-time updates
monitoring_offloaded_work:
  river_queue_metrics:
  - metric: river_jobs_total{state="completed"}
    description: Total completed jobs
  - metric: river_jobs_total{state="failed"}
    description: Total failed jobs
  - metric: river_job_duration_seconds
    description: Job processing time
  dragonfly_metrics:
  - metric: dragonfly_connected_clients
    description: Active connections
  - metric: dragonfly_keyspace_hits
    description: Cache hits
  - metric: dragonfly_keyspace_misses
    description: Cache misses
  - metric: dragonfly_used_memory_bytes
    description: Memory usage
  typesense_metrics:
  - metric: typesense_search_requests_total
    description: Search queries
  - metric: typesense_search_latency_seconds
    description: Search latency
configuration:
  river_workers:
    pool_size: 10 workers per instance
    max_concurrent_jobs: 50
    priority_queues: true (critical, high, normal, low)
  dragonfly_cache:
    max_memory: 4GB
    eviction_policy: allkeys-lru
    persistence: Snapshot every 5 minutes
  typesense_search:
    nodes: 3 (HA cluster)
    memory_per_node: 8GB
    replication_factor: 2
best_practices:
- practice: Return 202 Accepted for async operations
  reason: Client knows operation is queued
- practice: Provide job status endpoint
  reason: Client can poll or subscribe for updates
- practice: Use WebSocket for real-time updates
  reason: Better UX than polling
- practice: Set realistic job timeouts
  reason: Avoid zombie jobs consuming resources
- practice: Implement job retries with exponential backoff
  reason: Handle transient failures gracefully
- practice: Monitor queue depth
  reason: Detect backlog early, scale workers
- practice: Cache aggressively
  reason: Reduce load on PostgreSQL and external APIs
- practice: Use Dragonfly for ephemeral data
  reason: Don't pollute PostgreSQL with temporary data
- practice: Offload search to Typesense
  reason: Better search experience, lower PostgreSQL load
- practice: Separate worker pools by priority
  reason: Critical jobs not blocked by low-priority work
