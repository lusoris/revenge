doc_title: Transcoding Service
doc_category: service
created_date: '2026-01-31'
overall_status: ‚úÖ Complete
status_design: ‚úÖ
status_design_notes: Complete transcoding service design
status_sources: ‚úÖ
status_sources_notes: All transcoding tools documented
status_instructions: ‚úÖ
status_instructions_notes: Generated from design
status_code: üî¥
status_code_notes: '-'
status_linting: üî¥
status_linting_notes: '-'
status_unit_testing: üî¥
status_unit_testing_notes: '-'
status_integration_testing: üî¥
status_integration_testing_notes: '-'
technical_summary: |-
  > On-demand video/audio transcoding service with hardware acceleration

  Transcoding capabilities:
  - **INTERNAL**: go-astiav FFmpeg bindings (default, always available)
  - **EXTERNAL**: Blackbeard service for optional offloading (third-party, not developed by us)
  - **Hardware Acceleration**: NVENC (NVIDIA), QSV (Intel), VAAPI (AMD)
  - **Adaptive Streaming**: HLS with multiple quality tiers
  - **Queue Management**: River background jobs for async processing
wiki_tagline: '> High-performance media transcoding with hardware acceleration'
wiki_overview: The Transcoding Service converts media files on-demand to ensure compatibility across all devices. **INTERNAL
  transcoding** uses go-astiav (FFmpeg Go bindings) with optional hardware acceleration (NVENC, QSV, VAAPI) and is always
  available. For heavy workloads, users can optionally configure **EXTERNAL offloading** to a Blackbeard service (third-party,
  not developed by us). Generates HLS adaptive streams with multiple quality levels, caching results for faster subsequent
  playback.
sources:
- name: go-astiav (FFmpeg)
  url: https://pkg.go.dev/github.com/asticode/go-astiav
  note: FFmpeg Go bindings
- name: gohlslib
  url: https://pkg.go.dev/github.com/bluenviron/gohlslib/v2
  note: HLS streaming library
- name: River Job Queue
  url: https://pkg.go.dev/github.com/riverqueue/river
  note: Background job processing
- name: Uber fx
  url: https://pkg.go.dev/go.uber.org/fx
  note: Dependency injection
design_refs:
- title: services
  path: INDEX.md
- title: 01_ARCHITECTURE
  path: ../architecture/01_ARCHITECTURE.md
- title: OFFLOADING
  path: ../technical/OFFLOADING.md
- title: AUDIO_STREAMING
  path: ../technical/AUDIO_STREAMING.md
service_name: Transcoding Service
package_path: internal/service/transcoding
fx_module: transcoding.Module
architecture_diagram: |-
  ```mermaid
  flowchart TD
      node1["Client<br/>(Web/App)"]
      node2["API Handler<br/>(ogen)"]
      node3["Service<br/>(Logic)"]
      node4["‚ñº<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>sitory"]
      node5["‚ñº<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>RNAL"]
      node6["Blackbeard"]
      node1 --> node2
      node2 --> node3
      node3 --> node4
      node4 --> node5
      node5 --> node6
  ```
database_schema: |
  **Schema**: `public`

  ```sql
  -- Transcode jobs
  CREATE TABLE transcode_jobs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- Content reference
    video_id UUID NOT NULL,                        -- References movies/episodes/etc.
    input_path TEXT NOT NULL,
    output_path TEXT NOT NULL,

    -- Profile
    profile VARCHAR(50) NOT NULL,                  -- '4k', '1080p', '720p', '480p'
    codec VARCHAR(20) NOT NULL,                    -- 'h264', 'hevc'

    -- Job status
    status VARCHAR(20) DEFAULT 'queued',           -- 'queued', 'processing', 'completed', 'failed', 'cancelled'
    progress_percent FLOAT DEFAULT 0,
    current_frame INTEGER,
    total_frames INTEGER,

    -- Execution details
    worker_type VARCHAR(50),                       -- 'blackbeard', 'local_nvenc', 'local_software'
    started_at TIMESTAMPTZ,
    completed_at TIMESTAMPTZ,
    error_message TEXT,

    -- Performance metrics
    transcode_duration_seconds INTEGER,
    file_size_bytes BIGINT,

    created_at TIMESTAMPTZ DEFAULT now()
  );
  CREATE INDEX idx_transcode_jobs_status ON transcode_jobs(status, created_at);
  CREATE INDEX idx_transcode_jobs_video ON transcode_jobs(video_id);

  -- Transcode cache (file-based cache metadata)
  CREATE TABLE transcode_cache (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- Cache key
    video_id UUID NOT NULL,
    profile VARCHAR(50) NOT NULL,
    checksum VARCHAR(64) NOT NULL,                 -- SHA-256 of input file
    cache_key VARCHAR(255) NOT NULL UNIQUE,

    -- Cached file
    file_path TEXT NOT NULL,
    file_size_bytes BIGINT NOT NULL,
    duration_seconds INTEGER,

    -- Cache management
    hit_count INTEGER DEFAULT 0,
    last_accessed_at TIMESTAMPTZ DEFAULT now(),
    created_at TIMESTAMPTZ DEFAULT now(),
    expires_at TIMESTAMPTZ DEFAULT now() + INTERVAL '7 days'
  );
  CREATE INDEX idx_transcode_cache_video ON transcode_cache(video_id, profile);
  CREATE INDEX idx_transcode_cache_expires ON transcode_cache(expires_at);
  CREATE INDEX idx_transcode_cache_lru ON transcode_cache(last_accessed_at);

  -- HLS segments (for adaptive streaming)
  CREATE TABLE hls_segments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    video_id UUID NOT NULL,
    profile VARCHAR(50) NOT NULL,

    -- Segment info
    segment_index INTEGER NOT NULL,
    file_path TEXT NOT NULL,
    duration_seconds FLOAT NOT NULL,

    created_at TIMESTAMPTZ DEFAULT now()
  );
  CREATE UNIQUE INDEX idx_hls_segments_unique ON hls_segments(video_id, profile, segment_index);
  ```
module_structure: |
  ```
  internal/service/transcoding/
  ‚îú‚îÄ‚îÄ module.go                    # fx module
  ‚îú‚îÄ‚îÄ types.go                     # Domain types
  ‚îú‚îÄ‚îÄ repository.go                # Database operations (sqlc)
  ‚îú‚îÄ‚îÄ service.go                   # Transcoding service logic
  ‚îú‚îÄ‚îÄ blackbeard.go                # Blackbeard client
  ‚îú‚îÄ‚îÄ ffmpeg.go                    # FFmpeg wrapper (go-astiav)
  ‚îú‚îÄ‚îÄ hardware.go                  # Hardware acceleration detection
  ‚îú‚îÄ‚îÄ profiles.go                  # Encoding profiles
  ‚îú‚îÄ‚îÄ hls.go                       # HLS manifest generation
  ‚îú‚îÄ‚îÄ cache.go                     # Cache management
  ‚îú‚îÄ‚îÄ worker.go                    # River worker
  ‚îú‚îÄ‚îÄ handler.go                   # HTTP API handlers
  ‚îî‚îÄ‚îÄ transcoding_test.go
  ```
key_interfaces: |
  ```go
  type TranscodingService interface {
    // Transcode operations
    QueueTranscode(ctx context.Context, videoID uuid.UUID, profile string) (*TranscodeJob, error)
    GetJob(ctx context.Context, jobID uuid.UUID) (*TranscodeJob, error)
    CancelJob(ctx context.Context, jobID uuid.UUID) error

    // Cache
    GetCachedVideo(ctx context.Context, videoID uuid.UUID, profile string) (string, error)
    ClearCache(ctx context.Context) error
    GetCacheStats(ctx context.Context) (*CacheStats, error)

    // HLS
    GenerateHLSManifest(ctx context.Context, videoID uuid.UUID) (string, error)
  }

  type Transcoder interface {
    Transcode(ctx context.Context, input, output string, profile Profile) error
    SupportsHardwareAccel() bool
    GetHardwareType() string
  }

  type TranscodeJob struct {
    ID              uuid.UUID  `db:"id" json:"id"`
    VideoID         uuid.UUID  `db:"video_id" json:"video_id"`
    Profile         string     `db:"profile" json:"profile"`
    Status          string     `db:"status" json:"status"`
    ProgressPercent float64    `db:"progress_percent" json:"progress_percent"`
    CreatedAt       time.Time  `db:"created_at" json:"created_at"`
  }
  ```
dependencies: |
  **Go Packages**:
  - `github.com/google/uuid`
  - `github.com/jackc/pgx/v5`
  - `github.com/asticode/go-astiav` - FFmpeg Go bindings
  - `github.com/bluenviron/gohlslib/v2` - HLS streaming
  - `github.com/riverqueue/river` - Background jobs
  - `go.uber.org/fx`

  **External Services**:
  - Blackbeard service (optional, for offloading)
  - FFmpeg (system dependency)
env_vars: |
  ```bash
  TRANSCODING_BLACKBEARD_URL=http://blackbeard:8080
  TRANSCODING_CACHE_DIR=/var/cache/revenge/transcoded
  TRANSCODING_CACHE_MAX_SIZE_GB=100
  TRANSCODING_HARDWARE_ACCEL=auto  # auto, nvenc, qsv, vaapi, none
  TRANSCODING_WORKERS=2
  ```
config_keys: |
  ```yaml
  transcoding:
    blackbeard:
      url: http://blackbeard:8080
      enabled: true
      timeout: 30s
    cache:
      dir: /var/cache/revenge/transcoded
      max_size_gb: 100
      ttl: 168h  # 7 days
    hardware:
      accel: auto
      prefer_nvenc: true
    workers: 2
    hls:
      segment_duration: 6s
  ```
unit_tests: |
  ```go
  func TestTranscodingService_QueueTranscode(t *testing.T) {
    // Test job queuing
  }

  func TestFFmpegTranscoder_HardwareDetection(t *testing.T) {
    // Test hardware acceleration detection
  }

  func TestHLS_ManifestGeneration(t *testing.T) {
    // Test HLS manifest creation
  }
  ```
integration_tests: |
  ```go
  func TestTranscoding_EndToEnd(t *testing.T) {
    // Test full transcode workflow
  }

  func TestTranscoding_CacheHit(t *testing.T) {
    // Test cache serving
  }
  ```
transcoding_targets:
  internal:
    name: Local FFmpeg (INTERNAL)
    description: go-astiav FFmpeg bindings for local transcoding (DEFAULT)
    library: go-astiav
    is_default: true
    advantages:
    - Always available, no external dependencies
    - Works offline
    - Full control over encoding
    - Supports hardware acceleration (NVENC, QSV, VAAPI)
    disadvantages:
    - Uses local CPU/GPU resources
    - May compete with other server tasks
  external:
    name: Blackbeard Service (EXTERNAL)
    description: Optional external transcoding service for offloading (NOT developed by us)
    protocol: HTTP API
    is_default: false
    developed_by_us: false
    advantages:
    - Dedicated transcoding hardware
    - No local CPU/GPU usage
    - Scales independently
    - Centralized resource management
    disadvantages:
    - Requires separate Blackbeard deployment
    - Third-party dependency
    - Network latency for job submission
    api_endpoint: http://blackbeard:8080/api/v1/transcode
    fallback: internal
hardware_acceleration:
  nvenc:
    vendor: NVIDIA
    codec: h264_nvenc, hevc_nvenc
    requirements: NVIDIA GPU with NVENC support
    performance: 5-10x faster than software encoding
    quality: Excellent at higher bitrates
    recommended: true
  qsv:
    vendor: Intel
    codec: h264_qsv, hevc_qsv
    requirements: Intel CPU with Quick Sync Video
    performance: 3-5x faster than software
    quality: Good
    recommended: true
  vaapi:
    vendor: AMD/Intel
    codec: h264_vaapi, hevc_vaapi
    requirements: Linux with VAAPI-compatible GPU
    performance: 3-5x faster than software
    quality: Good
    recommended: For AMD GPUs
  software:
    codec: libx264, libx265
    performance: Slowest (baseline)
    quality: Best (most flexible tuning)
    use_case: Fallback when no hardware available
video_transcoding:
  supported_input_codecs:
  - H.264 (AVC)
  - H.265 (HEVC)
  - VP9
  - AV1
  - MPEG-2
  - MPEG-4
  output_profiles:
  - profile: 4K HEVC
    codec: hevc
    resolution: 3840x2160
    bitrate: 20 Mbps
    preset: medium
    use_case: High-quality playback
  - profile: 1080p H.264
    codec: h264
    resolution: 1920x1080
    bitrate: 8 Mbps
    preset: fast
    use_case: Standard streaming
  - profile: 720p H.264
    codec: h264
    resolution: 1280x720
    bitrate: 4 Mbps
    preset: faster
    use_case: Mobile/low bandwidth
  - profile: 480p H.264
    codec: h264
    resolution: 854x480
    bitrate: 1.5 Mbps
    preset: veryfast
    use_case: Very low bandwidth
audio_transcoding:
  supported_input_codecs:
  - MP3
  - AAC
  - FLAC
  - Opus
  - Vorbis
  - AC3
  - DTS
  output_profiles:
  - profile: AAC Stereo
    codec: aac
    bitrate: 128 kbps
    channels: 2
    sample_rate: 48000
    preferred: true
  - profile: Opus
    codec: opus
    bitrate: 96 kbps
    channels: 2
    sample_rate: 48000
    use_case: Low bandwidth
hls_streaming:
  segment_duration: 6 seconds
  target_duration: 6
  playlist_type: VOD
  quality_ladder:
  - name: Low
    resolution: 640x360
    video_bitrate: 800 kbps
    audio_bitrate: 64 kbps
    bandwidth: 864000
  - name: Medium
    resolution: 1280x720
    video_bitrate: 2500 kbps
    audio_bitrate: 128 kbps
    bandwidth: 2628000
  - name: High
    resolution: 1920x1080
    video_bitrate: 5000 kbps
    audio_bitrate: 192 kbps
    bandwidth: 5192000
  - name: Ultra
    resolution: 3840x2160
    video_bitrate: 15000 kbps
    audio_bitrate: 256 kbps
    bandwidth: 15256000
  manifest_generation: |
    ```go
    func GenerateHLSManifest(qualities []Quality) string {
        var manifest strings.Builder
        manifest.WriteString("#EXTM3U\n")
        manifest.WriteString("#EXT-X-VERSION:3\n\n")

        for _, q := range qualities {
            manifest.WriteString(fmt.Sprintf("#EXT-X-STREAM-INF:BANDWIDTH=%d,RESOLUTION=%s\n",
                q.Bandwidth, q.Resolution))
            manifest.WriteString(fmt.Sprintf("%s/playlist.m3u8\n", q.Name))
        }

        return manifest.String()
    }
    ```
transcoding_pipeline:
  job_creation: |
    ```go
    type TranscodeVideoArgs struct {
        VideoID    uuid.UUID `json:"video_id"`
        InputPath  string    `json:"input_path"`
        OutputPath string    `json:"output_path"`
        Profile    string    `json:"profile"` // 1080p, 720p, etc.
        Priority   int       `json:"priority"`
    }

    func (s *TranscodingService) QueueTranscode(ctx context.Context, videoID uuid.UUID, profile string) error {
        video, err := s.repo.GetByID(ctx, videoID)
        if err != nil {
            return err
        }

        _, err = s.riverClient.Insert(ctx, &TranscodeVideoArgs{
            VideoID:    videoID,
            InputPath:  video.FilePath,
            OutputPath: s.getOutputPath(videoID, profile),
            Profile:    profile,
            Priority:   2, // Normal priority
        }, nil)

        return err
    }
    ```
  worker_implementation: |
    ```go
    type TranscodeVideoWorker struct {
        river.WorkerDefaults[TranscodeVideoArgs]
        transcoder *Transcoder
        repo       VideoRepository
    }

    func (w *TranscodeVideoWorker) Work(ctx context.Context, job *river.Job[TranscodeVideoArgs]) error {
        slog.Info("starting transcode",
            "video_id", job.Args.VideoID,
            "profile", job.Args.Profile)

        // Try Blackbeard first
        if w.transcoder.BlackbeardAvailable() {
            err := w.transcoder.TranscodeViaBlackbeard(ctx, job.Args)
            if err == nil {
                return nil
            }
            slog.Warn("blackbeard transcode failed, falling back to local", "error", err)
        }

        // Fallback to local FFmpeg
        return w.transcoder.TranscodeLocal(ctx, job.Args)
    }
    ```
  ffmpeg_command: |
    ```go
    func (t *Transcoder) TranscodeLocal(ctx context.Context, args *TranscodeVideoArgs) error {
        profile := t.profiles[args.Profile]

        cmd := ffmpeg.New().
            Input(args.InputPath).
            VideoCodec(profile.VideoCodec).
            VideoBitrate(profile.VideoBitrate).
            AudioCodec(profile.AudioCodec).
            AudioBitrate(profile.AudioBitrate).
            Scale(profile.Width, profile.Height).
            Output(args.OutputPath)

        // Add hardware acceleration if available
        if t.hwAccel != nil {
            cmd = cmd.HardwareAccel(t.hwAccel)
        }

        return cmd.Run(ctx)
    }
    ```
caching_strategy: |-
  File-based cache with LRU eviction:
  - Location: /var/cache/revenge/transcoded/
  - TTL: 7 days
  - Key format: ${video_id}_${profile}_${checksum}
  - Max size: 100 GB
cache_keys: |-
  ```
  ${video_id}_${profile}_${checksum}  # Transcoded video files
  ```
cache_check: |
  ```go
  func (s *TranscodingService) GetTranscodedVideo(ctx context.Context, videoID uuid.UUID, profile string) (string, error) {
      cacheKey := s.getCacheKey(videoID, profile)
      cachedPath := s.cachePath(cacheKey)

      // Check if cached version exists
      if _, err := os.Stat(cachedPath); err == nil {
          slog.Info("serving from cache", "video_id", videoID, "profile", profile)
          return cachedPath, nil
      }

      // Not cached, queue transcoding job
      err := s.QueueTranscode(ctx, videoID, profile)
      if err != nil {
          return "", err
      }

      // Wait for transcode to complete (with timeout)
      return s.waitForTranscode(ctx, cacheKey, 5*time.Minute)
  }
  ```
progress_tracking:
  method: WebSocket updates via /api/v1/ws/transcode/:job_id
  update_frequency: Every 2 seconds
  metrics:
  - progress_percent (0-100)
  - current_frame
  - total_frames
  - fps (frames per second)
  - eta_seconds (estimated time remaining)
  websocket_message: |
    ```json
    {
      "type": "transcode.progress",
      "job_id": "uuid-here",
      "progress": 45.5,
      "current_frame": 12345,
      "total_frames": 27000,
      "fps": 120.5,
      "eta_seconds": 180
    }
    ```
api_endpoints:
- method: POST
  path: /api/v1/transcode/video/:id
  description: Start video transcoding
  request: |
    {
      "profile": "1080p",
      "priority": "normal"
    }
  response: |
    {
      "job_id": "uuid-here",
      "status": "queued"
    }
- method: GET
  path: /api/v1/transcode/job/:job_id
  description: Get transcode job status
  response: |
    {
      "job_id": "uuid-here",
      "status": "processing",
      "progress": 45.5,
      "eta_seconds": 180
    }
- method: DELETE
  path: /api/v1/transcode/job/:job_id
  description: Cancel transcode job
- method: GET
  path: /api/v1/transcode/cache/stats
  description: Get cache statistics
  response: |
    {
      "size_bytes": 85000000000,
      "max_size_bytes": 100000000000,
      "item_count": 523,
      "hit_rate": 0.78
    }
best_practices:
- practice: Offload to Blackbeard when available
  reason: Saves local resources, faster transcoding
- practice: Use hardware acceleration
  reason: 5-10x faster with minimal quality loss
- practice: Cache transcoded outputs
  reason: Instant playback on subsequent requests
- practice: Generate HLS adaptive streams
  reason: Optimal quality for each network condition
- practice: Monitor transcode queue depth
  reason: Scale workers when queue grows
- practice: Set appropriate job priorities
  reason: User-requested transcodes before background
- practice: Implement timeout and cancellation
  reason: Don't waste resources on stalled jobs
