# A8.1.2 Implementation: S3 Storage for Avatars

**Status**: ✅ COMPLETE
**Date**: 2026-02-05
**Priority**: P0 (Critical - Cluster Readiness)

## Overview

Implemented S3-compatible storage backend for user-generated content (avatars), enabling cluster deployments where multiple Revenge instances share the same storage. Supports AWS S3, MinIO, and any S3-compatible object storage.

## Changes Made

### 1. S3 Storage Implementation

#### internal/service/storage/s3.go (NEW)
Full S3Storage implementation with:
- AWS SDK v2 integration
- MinIO compatibility (path-style URLs)
- Custom endpoint support
- All Storage interface methods implemented:
  - `Store()` - Upload files to S3
  - `Get()` - Retrieve files from S3
  - `Delete()` - Remove files from S3
  - `Exists()` - Check file existence
  - `GetURL()` - Generate S3 URLs

**Key Features**:
- Static credentials provider
- Custom endpoint for MinIO
- Path-style URL support (required for MinIO)
- Bucket verification health check
- Sanitized keys for security

### 2. Configuration

#### internal/config/config.go
Added comprehensive storage configuration:

```go
type StorageConfig struct {
    Backend string  // "local" or "s3"
    Local   LocalStorageConfig
    S3      S3Config
}

type S3Config struct {
    Endpoint        string  // MinIO: "http://minio:9000"
    Region          string  // "us-east-1"
    Bucket          string  // "revenge-avatars"
    AccessKeyID     string
    SecretAccessKey string
    UsePathStyle    bool    // true for MinIO
}
```

**Defaults**:
- `storage.backend`: "local" (backwards compatible)
- `storage.local.path`: "/data/storage"
- `storage.s3.region`: "us-east-1"
- `storage.s3.use_path_style`: false

### 3. Module Updates

#### internal/service/storage/module.go
Enhanced provider with backend selection:
- Switch between "local" and "s3" backends
- Backwards compatibility with Avatar.StoragePath
- Logging for visibility
- Fallback to local on unknown backend

### 4. Dependencies

Added AWS SDK v2 packages:
```
github.com/aws/aws-sdk-go-v2 v1.41.1
github.com/aws/aws-sdk-go-v2/config v1.32.7
github.com/aws/aws-sdk-go-v2/credentials v1.19.7
github.com/aws/aws-sdk-go-v2/service/s3 v1.96.0
```

Plus transitive dependencies for SSO, STS, etc.

### 5. Docker Compose with MinIO

#### docker-compose.s3.yml (NEW)
Complete MinIO deployment with:
- MinIO server (S3-compatible storage)
- MinIO console (web UI on :9001)
- Automatic bucket creation (minio-init service)
- Public download policy for avatars
- Health checks and dependencies
- Environment variable configuration

**Services**:
1. **minio**: Object storage server
2. **minio-init**: One-time bucket setup
3. **revenge**: Updated with S3 environment variables

**Usage**:
```bash
docker-compose -f docker-compose.yml -f docker-compose.s3.yml up
```

**Access**:
- MinIO Console: http://localhost:9001
- MinIO API: http://localhost:9000
- Default credentials: minioadmin/minioadmin

## Architecture

### Storage Backend Selection

```
Config: storage.backend = "s3"
         ↓
provideStorage() in module.go
         ↓
NewS3Storage(cfg.Storage.S3, logger)
         ↓
S3Storage with AWS SDK v2
         ↓
MinIO/S3 bucket
```

### Hybrid Storage Model

**Media Files** (movies, TV):
- Storage: NFS (read-only, shared)
- Use Case: Large, static content
- Why: Better performance for streaming
- Implemented: A8.1.1

**User Content** (avatars):
- Storage: S3/MinIO (read-write, shared)
- Use Case: Small, dynamic content
- Why: Better for distributed writes, object metadata
- Implemented: A8.1.2 (this)

### S3 vs Local Comparison

| Feature | Local Storage | S3 Storage |
|---------|---------------|------------|
| **Cluster Support** | No (single node) | Yes (all nodes) |
| **Scalability** | Limited to disk | Virtually unlimited |
| **Cost** | Disk space only | Pay per GB + requests |
| **Performance** | Fast (local disk) | Network latency |
| **Durability** | Depends on disk | 99.999999999% (11 9's) |
| **Backup** | Manual | Built-in versioning |
| **Setup** | Simple | Requires S3/MinIO |

## Configuration Examples

### Production with AWS S3

```yaml
storage:
  backend: s3
  s3:
    region: us-west-2
    bucket: revenge-production-avatars
    access_key_id: AKIA...
    secret_access_key: xxx
    use_path_style: false
```

### Development with MinIO

```yaml
storage:
  backend: s3
  s3:
    endpoint: http://minio:9000
    region: us-east-1
    bucket: revenge-avatars
    access_key_id: minioadmin
    secret_access_key: minioadmin
    use_path_style: true
```

### Backwards Compatible Local

```yaml
storage:
  backend: local
  local:
    path: /data/storage

# Or use legacy avatar config:
avatar:
  storage_path: /data/avatars
```

## Testing

### Manual Validation Checklist

- [ ] S3Storage builds without errors
- [ ] Config validates with s3 backend
- [ ] MinIO starts and bucket created
- [ ] Avatar upload works with S3
- [ ] Avatar retrieval works from S3
- [ ] Avatar deletion works
- [ ] URL generation correct (path-style for MinIO)
- [ ] Fallback to local if S3 unavailable
- [ ] Multiple Revenge instances share storage

### Test Scenarios

**Scenario 1: Local Development**
```bash
# Default config - use local storage
docker-compose up
# Avatars stored in /data/avatars
```

**Scenario 2: MinIO Development**
```bash
# Use S3 with MinIO
docker-compose -f docker-compose.yml -f docker-compose.s3.yml up

# Access MinIO console
open http://localhost:9001

# Upload avatar, verify in MinIO console
```

**Scenario 3: Multiple Replicas**
```bash
docker-compose -f docker-compose.yml -f docker-compose.s3.yml up --scale revenge=3

# All 3 instances use same S3 bucket
# Upload on instance 1, visible on all instances
```

**Scenario 4: AWS S3 Production**
```bash
# Set environment variables
export REVENGE_STORAGE_BACKEND=s3
export REVENGE_STORAGE_S3_REGION=us-west-2
export REVENGE_STORAGE_S3_BUCKET=my-bucket
export REVENGE_STORAGE_S3_ACCESS_KEY_ID=AKIA...
export REVENGE_STORAGE_S3_SECRET_ACCESS_KEY=xxx

# Run
./revenge
```

## Benefits

### Cluster-Ready Storage
- **Shared Storage**: All instances access same bucket
- **No Sync Needed**: S3 is already distributed
- **Horizontal Scaling**: Add instances without storage concerns

### S3 Advantages
- **Durability**: 11 9's data durability
- **Availability**: 99.99% availability SLA
- **Scalability**: Unlimited storage capacity
- **Features**: Versioning, lifecycle policies, CDN integration

### MinIO for Self-Hosted
- **S3 Compatible**: Drop-in replacement for AWS S3
- **Self-Hosted**: No cloud vendor lock-in
- **Cost Effective**: Use existing infrastructure
- **Easy Setup**: Single Docker container

### Backwards Compatible
- **Default**: Local storage (no breaking changes)
- **Migration Path**: Switch backend via config
- **Hybrid**: Can run both (local for dev, S3 for prod)

## Migration Guide

### From Local to S3

1. **Setup S3/MinIO**
   - AWS: Create S3 bucket
   - Self-hosted: Deploy MinIO

2. **Update Configuration**
   ```yaml
   storage:
     backend: s3
     s3:
       endpoint: http://minio:9000  # Or leave empty for AWS
       region: us-east-1
       bucket: revenge-avatars
       access_key_id: xxx
       secret_access_key: xxx
       use_path_style: true  # For MinIO
   ```

3. **Migrate Existing Avatars** (optional)
   ```bash
   # Use AWS CLI or MinIO mc
   aws s3 sync /data/avatars/ s3://revenge-avatars/avatars/
   # Or with mc
   mc cp --recursive /data/avatars minio/revenge-avatars/avatars
   ```

4. **Test**
   - Upload new avatar
   - Verify in S3 console
   - Retrieve avatar via API

5. **Deploy to Cluster**
   - All pods use same S3 config
   - Shared storage automatically

## Security Considerations

### Credentials Management
- **Don't commit**: Never commit S3 credentials to git
- **Use secrets**: K8s Secrets, AWS IAM roles, or env vars
- **Rotate regularly**: Change access keys periodically

### Bucket Policies
- **Private bucket**: Don't make bucket public
- **Pre-signed URLs**: Use for temporary access (future enhancement)
- **IAM roles**: Use EC2/EKS IAM roles in production

### Network Security
- **VPC endpoints**: Use for AWS S3 in VPC
- **TLS**: Always use HTTPS for S3 (except MinIO localhost)
- **Firewall**: Restrict MinIO access to internal network

## Future Enhancements

### Planned
- **Pre-signed URLs**: For private buckets with temporary access
- **CDN Integration**: CloudFront or equivalent for avatar delivery
- **Image Processing**: Resize/optimize on upload
- **Versioning**: Keep avatar history

### Possible
- **Multi-region**: Replicate across regions for DR
- **Lifecycle Policies**: Auto-delete old avatars
- **Encryption**: Server-side or client-side encryption
- **Metrics**: Track storage usage, costs

## Troubleshooting

### MinIO not accessible
```bash
# Check MinIO is running
docker ps | grep minio

# Check MinIO logs
docker logs revenge-minio

# Check bucket exists
docker exec revenge-minio-init mc ls minio
```

### S3 upload fails
```bash
# Check credentials
env | grep REVENGE_STORAGE

# Check bucket access
aws s3 ls s3://your-bucket/

# Check Revenge logs
docker logs revenge | grep storage
```

### Avatars not appearing
```bash
# Check storage backend in use
docker logs revenge | grep "Using.*storage backend"

# List files in bucket
aws s3 ls s3://revenge-avatars/avatars/ --recursive

# Or with MinIO
docker exec revenge-minio-init mc ls minio/revenge-avatars/avatars/
```

## References

- AWS SDK Go v2: https://aws.github.io/aws-sdk-go-v2/docs/
- MinIO Documentation: https://min.io/docs/minio/linux/
- S3 API Reference: https://docs.aws.amazon.com/s3/
- MinIO mc Client: https://min.io/docs/minio/linux/reference/minio-mc.html

---

**Phase A8.1.2 Complete**: S3-compatible storage implemented for cluster-ready avatar storage.
